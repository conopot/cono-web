<div>Teachable Machine Audio Model</div>
<button type="button" onclick="init()">Start</button>
<button type="button" onclick="stop()">Stop</button>
<button type="button" onclick="inference()">결과보기</button>
<div id="label-container"></div>
<h1></h1>
<p></p>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>

<script type="text/javascript">
    // more documentation available at
    // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://teachablemachine.withgoogle.com/models/ZHjjyd5ts/";

    let status = "배경 소음";
    let current = document.getElementsByTagName("p")[0];    // 현재 음악
    let electronic = document.getElementsByTagName("p")[1]; // 전자 음악이 몇 초동안 지속되었는지

    let recognizer;
    let classLabels;
    let scoreBySinger; // 각 가수별 score 누적 합

    async function createModel() {
        const checkpointURL = URL + "model.json"; // model topology
        const metadataURL = URL + "metadata.json"; // model metadata

        const recognizer = speechCommands.create(
            "BROWSER_FFT", // fourier transform type, not useful to change
            undefined, // speech commands vocabulary feature, not useful for your models
            checkpointURL,
            metadataURL);

        // check that model and metadata are loaded via HTTPS requests.
        await recognizer.ensureModelLoaded();

        return recognizer;
    }

    async function init() {
        // const recognizer = await createModel();
        recognizer = await createModel();
        classLabels = recognizer.wordLabels(); // get class labels
        const labelContainer = document.getElementById("label-container");
        for (let i = 0; i < classLabels.length; i++) {
            labelContainer.appendChild(document.createElement("div"));
        }
        // timer(); // 몇 초 동안 "지속"되는지 확인하기 위한 함수

        // 각 가수당 몇 점을 얻었는지 저장
        scoreBySinger = [];
        for(let i=0; i < classLabels.length; i++) { // init arr
            scoreBySinger.push(0.0);
        }

        // listen() takes two arguments:
        // 1. A callback function that is invoked anytime a word is recognized. // 단어가 인식 될 때마다 호출
        // 2. A configuration object with adjustable fields
        recognizer.listen(result => {
            const scores = result.scores; // probability of prediction for each class

            // render the probability scores per class
            for (let i = 0; i < classLabels.length; i++) {
                const classPrediction = classLabels[i] + ": " + result.scores[i].toFixed(2);
                scoreBySinger[i] += result.scores[i];
                labelContainer.childNodes[i].innerHTML = classPrediction; // 이번 Turn(1초)에 각 label들이 몇 점을 얻었는지 ex) 10cm: 0.06
            }

            // 누적이 제대로 되고 있는지 출력하는 코드
            // for (let i = 0; i < classLabels.length; i++) {
            //     console.log(classLabels[i] + " : " + scoreBySinger[i]);
            // }

            // 여기는 추가된 코드인데 즉 0.8점 이상이면 현재음으로 출력함 -> 해당 로직 변경 필요
            if(0.8 <= result.scores[0]) {           
                status = classLabels[0];
            } else if(0.8 <= result.scores[1]) {    
                status = classLabels[1];
            } else if(0.8 <= result.scores[2]) {    
                status = classLabels[2];
            } else if(0.8 <= result.scores[3]) {    
                status = classLabels[3];
            } else if(0.8 <= result.scores[4]) {    
                status = classLabels[4];
            } else {                                
                status = classLabels[5];
            }

            current.innerHTML = "현재 : " + status;
        }, {
            includeSpectrogram: true, // in case listen should return result.spectrogram
            probabilityThreshold: 0.75,
            invokeCallbackOnNoiseAndUnknown: true,
            overlapFactor: 0.50 // probably want between 0.5 and 0.75. More info in README
        });

        // Stop the recognition in 10 seconds.
        setTimeout(() => recognizer.stopListening(), 10000);
    }

    // listen 중단
    function stop() {
        recognizer.stopListening();
        console.log("Stop Listening");
    }

    function inference() {
        // 점수 배열 돌면서 가장 높은 점수를 받은 가수를 출력 -> 이 때 배경소음 제외
        let cmp = -1.0;
        for (let i = 0; i < classLabels.length; i++) {
            // console.log(i + " : " + classLabels[i]);
            if(classLabels[i] === '배경 소음') continue;
            if(cmp < scoreBySinger[i]) {
                status = classLabels[i];
                cmp = scoreBySinger[i];
            } 
        }

        console.log("Max Score : " + cmp);
        // 만약 최고점수가 0점이면, 다시 측정하라고 처리해주기 !!!!
        current.innerHTML = "최고점수 : " + status;
    }

    function timer() {
        let second = 0;

        let time = setInterval(function() {
            if(status == "Electronic") {    // 현재 상태가 Electronic 이라면
                second++;            
            } else {
                second = 0;
            }

            // electronic.innerHTML = "전자 음악이 지속된 시간 : " + second + "초";
        }, 1000);
    }
</script>
